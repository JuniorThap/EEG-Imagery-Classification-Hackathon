{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# If the dataset is gated/private, make sure you have run huggingface-cli login\n",
    "dataset = load_dataset(\"Expss4/EXP-Last-Place\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.set_format(type='torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {110:0, 120:1, 150:2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapmap(row):\n",
    "    return {'data': row['data'].unsqueeze(0).unsqueeze(0), 'label': id2label(int(row['label']))}\n",
    "\n",
    "dataset['train'] = dataset['train'].map()\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train']['label'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset['train'].train_test_split(0.2)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(dataset['train']['data'][0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# arrs = torch.tensor(dataset['train']['arr']).reshape(5556, 8, 865)\n",
    "# arrs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = torch.tensor(dataset['train']['label']).reshape(5556, 8, 1)\n",
    "# labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = [label for label in labels]\n",
    "# len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import Dataset\n",
    "# new_dataset = Dataset.from_dict({'arr': arrs, 'label': labels})\n",
    "# new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_dataset.push_to_hub('Expss4/train_seq_pre_gj_8in1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# np.array(dataset['train']['processed'][0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import load_dataset\n",
    "\n",
    "# # If the dataset is gated/private, make sure you have run huggingface-cli login\n",
    "# dataset = load_dataset(\"Expss4/train_seq_pre_gj_8in1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = dataset['train'].train_test_split(0.2)\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset['train']['label'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def go_out(example):\n",
    "#     return {'label':example['label'][0][0]}\n",
    "# dataset = dataset.map(go_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.push_to_hub('Expss4/train_seq_pre_gj_8in1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# class Loader(Dataset):\n",
    "#     def __init__(self, datadict=None):\n",
    "#         self.datadict = datadict\n",
    "#         self.datadict.set_format(type='torch')\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.datadict)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         data = self.datadict['data'][idx].unsqueeze(0).unsqueeze(0)\n",
    "#         label = id2label[int(self.datadict['label'][idx])]\n",
    "#         return {'data':data, 'label':label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader = DataLoader(Loader(dataset['train']), batch_size=2)\n",
    "# val_loader = DataLoader(Loader(dataset['test']), batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, padding):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels, kernel_size, padding=padding),\n",
    "            nn.Conv2d(in_channels, in_channels, kernel_size, padding=padding),\n",
    "            nn.GELU(),\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.Dropout2d(0.2),\n",
    "            nn.Conv2d(in_channels, in_channels, kernel_size, padding=padding),\n",
    "            nn.Conv2d(in_channels, in_channels, kernel_size, padding=padding),\n",
    "            nn.GELU(),\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.Dropout2d(0.2),\n",
    "            nn.Conv2d(in_channels, in_channels, kernel_size, padding=padding),\n",
    "            nn.Conv2d(in_channels, in_channels, kernel_size, padding=padding),\n",
    "            nn.SiLU(),\n",
    "        )\n",
    "\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, padding=padding)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y = self.cnn(x)\n",
    "        y += x\n",
    "        y = self.out(y)\n",
    "\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RealResnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.res_1 = ResidualBlock(1, 3, 3, 1)\n",
    "        self.res_2 = ResidualBlock(3, 3, 5, 2)\n",
    "        self.res_3 = ResidualBlock(3, 8, 5, 2)\n",
    "        self.res_4 = ResidualBlock(8, 8, 5, 2)\n",
    "        self.maxpool2d_5 = nn.MaxPool2d(2)\n",
    "        \n",
    "        # self.res_6 = ResidualBlock(8, 16, 3, 1)\n",
    "        # self.res_7 = ResidualBlock(16, 16, 5, 2)\n",
    "        # self.res_8 = ResidualBlock(16, 32, 5, 2)\n",
    "        # self.res_9 = ResidualBlock(32, 32, 5, 2)\n",
    "        # self.maxpool2d_10 = nn.MaxPool2d(2)\n",
    "        \n",
    "        # self.res_11 = ResidualBlock(32, 64, (1, 7), (0, 3))\n",
    "        # self.res_12 = ResidualBlock(64, 64, (1, 7), (0, 3))\n",
    "        # self.res_13 = ResidualBlock(64, 128, (1, 9), (0, 4))\n",
    "        # self.res_14 = ResidualBlock(128, 128, (1, 9), (0, 4))\n",
    "        # self.maxpool2d_15 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.classify_16 = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(288, 128),\n",
    "            nn.ReLU(),\n",
    "            # nn.Linear(2048, 512),\n",
    "            nn.Dropout(0.2),\n",
    "            # nn.ReLU(),\n",
    "            nn.Linear(128, 3),\n",
    "            nn.Softmax(),\n",
    "        )\n",
    "  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.res_1(x)\n",
    "        x = self.res_2(x)\n",
    "        x = self.res_3(x)\n",
    "        x = self.res_4(x)\n",
    "        x = self.maxpool2d_5(x)\n",
    "        \n",
    "        # x = self.res_6(x)\n",
    "        # x = self.res_7(x)\n",
    "        # x = self.res_8(x)\n",
    "        # x = self.res_9(x)\n",
    "        # x = self.maxpool2d_10(x)\n",
    "        \n",
    "        # x = self.res_11(x)\n",
    "        # x = self.res_12(x)\n",
    "        # x = self.res_13(x)\n",
    "        # x = self.res_14(x)\n",
    "        # x = self.maxpool2d_15(x)\n",
    "\n",
    "        x = self.classify_16(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# model = RealResnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "model = torch.load('tst_model103.pt') # best model\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchsummary\n",
    "\n",
    "torchsummary.summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.empty(8, 18).unsqueeze(0).unsqueeze(0)\n",
    "print(input.size())\n",
    "model(input).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('tst_model103.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class c1dT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(8, 32, 1),\n",
    "            nn.Conv1d(32, 32, 3),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout2d(),\n",
    "            nn.Conv1d(32, 64, 3),\n",
    "            nn.Conv1d(64, 128, 3),\n",
    "            nn.SiLU(),\n",
    "        )\n",
    "        self.flatten = nn.Flatten(0, -1)\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Linear(1536, 1024),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.Dropout(),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(128, 3),\n",
    "            nn.Softmax(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense(x)\n",
    "        return x\n",
    "\n",
    "model = c1dT()\n",
    "input = torch.empty([8, 18])\n",
    "print(input.size())\n",
    "model(input).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class smallres(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.res_1 = ResidualBlock(1, 3, 3, 1)\n",
    "        self.res_2 = ResidualBlock(3, 3, 5, 2)\n",
    "\n",
    "        self.flatten = nn.Flatten(0, -1)\n",
    "\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.LayerNorm(432),\n",
    "            nn.Linear(432, 512),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(512, 432),\n",
    "            nn.Dropout(),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(432, 128),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(128, 3),\n",
    "            nn.Softmax()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.res_1(x)\n",
    "        x = self.res_2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense(x)\n",
    "        return x\n",
    "\n",
    "# model = smallres()\n",
    "# input = torch.empty([1, 1, 8, 18])\n",
    "# print(input.size())\n",
    "# model(input).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('smallres_model_a134.pt')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_2 = torch.empty([8, 18]).to(device)\n",
    "input.size(), input_2.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input.size()\n",
    "\n",
    "model(input_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('tst_model99.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Model 103\n",
    "from tqdm import tqdm\n",
    "from torch.optim import AdamW\n",
    "from sklearn.metrics import f1_score \n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "torch.backends.cudnn.benchmark =  True\n",
    "torch.backends.cudnn.enabled =  True\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available else 'cpu'\n",
    "\n",
    "early_stop_patients = 22\n",
    "patients_count = 0\n",
    "\n",
    "# Fine-tuning parameters\n",
    "num_epochs = 150\n",
    "optimizer = AdamW(model.parameters(), lr=5e-4, weight_decay=0.01)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=150)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "model.to(device)\n",
    "# scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "total_train_loss = []\n",
    "total_test_loss = []\n",
    "total_f1 = []\n",
    "\n",
    "maxf1 = 0\n",
    "# Fine-tuning loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_avg_loss = 0\n",
    "    ty_true = []\n",
    "    ty_pred = []\n",
    "    for idx, row in tqdm(enumerate(dataset['train']), total=len(dataset['train'])):\n",
    "      torch.cuda.empty_cache()\n",
    "\n",
    "      input = torch.tensor(row['data']).unsqueeze(0).unsqueeze(0).to(device)\n",
    "      label = id2label[int(row['label'])]\n",
    "\n",
    "      outputs = model(input).squeeze()\n",
    "      loss = loss_fn(outputs, F.one_hot(torch.tensor(label), 3).float().to(device))\n",
    "      # scaler.scale(loss).backward()\n",
    "      loss.backward()\n",
    "\n",
    "      ty_true.append(label)\n",
    "      ty_pred.append(torch.argmax(outputs.to('cpu'), -1))\n",
    "\n",
    "      if (idx % 128) == 0:\n",
    "        # scaler.step(optimizer)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        # scaler.update()\n",
    "      train_avg_loss += loss.item()\n",
    "    train_avg_loss /= len(dataset['train'])\n",
    "    total_train_loss.append(train_avg_loss)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    test_avg_loss = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "      for idx, row in tqdm(enumerate(dataset['test']), total=len(dataset['test'])):\n",
    "\n",
    "        input = torch.tensor(row['data']).unsqueeze(0).unsqueeze(0).to(device)\n",
    "        label = id2label[int(row['label'])]\n",
    "\n",
    "        val_outputs = model(input).squeeze()\n",
    "        val_loss = loss_fn(val_outputs, F.one_hot(torch.tensor(label), 3).float().to(device))\n",
    "\n",
    "        y_true.append(label)\n",
    "        y_pred.append(torch.argmax(val_outputs.to('cpu'), -1))\n",
    "        \n",
    "        test_avg_loss += val_loss.item()\n",
    "          \n",
    "      test_avg_loss /= len(dataset['test'])\n",
    "      total_test_loss.append(test_avg_loss)\n",
    "\n",
    "      f1score = f1_score(y_true=y_true, y_pred=y_pred, average='macro')\n",
    "      total_f1.append(f1score)\n",
    "\n",
    "      print(f\"Epoch {epoch+1}/{num_epochs}: Avg Loss: {train_avg_loss}, Avg Val Loss: {test_avg_loss}, \\ntF1_score: {f1_score(y_true=ty_true, y_pred=ty_pred, average='macro')}, vF1_score: {f1score}\")\n",
    "      \n",
    "      # early stop\n",
    "      \n",
    "      torch.save(model, f'tst_model{epoch+100}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Model\n",
    "from tqdm import tqdm\n",
    "from torch.optim import AdamW\n",
    "from sklearn.metrics import f1_score \n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "torch.backends.cudnn.benchmark =  True\n",
    "torch.backends.cudnn.enabled =  True\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available else 'cpu'\n",
    "\n",
    "early_stop_patients = 22\n",
    "patients_count = 0\n",
    "\n",
    "# Fine-tuning parameters\n",
    "num_epochs = 150\n",
    "optimizer = AdamW(model.parameters(), lr=5e-4, weight_decay=0.01)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=150)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "model.to(device)\n",
    "# scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "total_train_loss = []\n",
    "total_test_loss = []\n",
    "total_f1 = []\n",
    "\n",
    "maxf1 = 0\n",
    "# Fine-tuning loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_avg_loss = 0\n",
    "    ty_true = []\n",
    "    ty_pred = []\n",
    "    for idx, row in tqdm(enumerate(dataset['train']), total=len(dataset['train'])):\n",
    "      torch.cuda.empty_cache()\n",
    "\n",
    "      input = torch.tensor(row['data']).to(device)\n",
    "      label = id2label[int(row['label'])]\n",
    "      outputs = model(input)\n",
    "      loss = loss_fn(outputs, F.one_hot(torch.tensor(label), 3).float().to(device))\n",
    "      # scaler.scale(loss).backward()\n",
    "      loss.backward()\n",
    "\n",
    "      ty_true.append(label)\n",
    "      ty_pred.append(torch.argmax(outputs.to('cpu'), -1))\n",
    "\n",
    "      if (idx % 128) == 0:\n",
    "        # scaler.step(optimizer)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        # scaler.update()\n",
    "      train_avg_loss += loss.item()\n",
    "    train_avg_loss /= len(dataset['train'])\n",
    "    total_train_loss.append(train_avg_loss)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    test_avg_loss = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "      for idx, row in tqdm(enumerate(dataset['test']), total=len(dataset['test'])):\n",
    "\n",
    "        input = torch.tensor(row['data']).to(device)\n",
    "        label = id2label[int(row['label'])]\n",
    "\n",
    "        val_outputs = model(input)\n",
    "        val_loss = loss_fn(val_outputs, F.one_hot(torch.tensor(label), 3).float().to(device))\n",
    "\n",
    "        y_true.append(label)\n",
    "        y_pred.append(torch.argmax(val_outputs.to('cpu'), -1))\n",
    "        \n",
    "        test_avg_loss += val_loss.item()\n",
    "          \n",
    "      test_avg_loss /= len(dataset['test'])\n",
    "      total_test_loss.append(test_avg_loss)\n",
    "\n",
    "      f1score = f1_score(y_true=y_true, y_pred=y_pred, average='macro')\n",
    "      total_f1.append(f1score)\n",
    "\n",
    "      print(f\"Epoch {epoch+1}/{num_epochs}: Avg Loss: {train_avg_loss}, Avg Val Loss: {test_avg_loss}, \\ntF1_score: {f1_score(y_true=ty_true, y_pred=ty_pred, average='macro')}, vF1_score: {f1score}\")\n",
    "      \n",
    "      # early stop\n",
    "      \n",
    "      torch.save(model, f'tst_model_a{epoch}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Model 2\n",
    "from tqdm import tqdm\n",
    "from torch.optim import AdamW\n",
    "from sklearn.metrics import f1_score \n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "torch.backends.cudnn.benchmark =  True\n",
    "torch.backends.cudnn.enabled =  True\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available else 'cpu'\n",
    "\n",
    "early_stop_patients = 22\n",
    "patients_count = 0\n",
    "\n",
    "# Fine-tuning parameters\n",
    "num_epochs = 150\n",
    "optimizer = AdamW(model.parameters(), lr=5e-4, weight_decay=0.01)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=150)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "model.to(device)\n",
    "# scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "total_train_loss = []\n",
    "total_test_loss = []\n",
    "total_f1 = []\n",
    "\n",
    "maxf1 = 0\n",
    "# Fine-tuning loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_avg_loss = 0\n",
    "    ty_true = []\n",
    "    ty_pred = []\n",
    "    for idx, row in tqdm(enumerate(dataset['train']), total=len(dataset['train'])):\n",
    "      torch.cuda.empty_cache()\n",
    "\n",
    "      input = torch.tensor(row['data']).unsqueeze(0).unsqueeze(0).to(device)\n",
    "      label = id2label[int(row['label'])]\n",
    "      outputs = model(input)\n",
    "      loss = loss_fn(outputs, F.one_hot(torch.tensor(label), 3).float().to(device))\n",
    "      # scaler.scale(loss).backward()\n",
    "      loss.backward()\n",
    "\n",
    "      ty_true.append(label)\n",
    "      ty_pred.append(torch.argmax(outputs.to('cpu'), -1))\n",
    "\n",
    "      if (idx % 128) == 0:\n",
    "        # scaler.step(optimizer)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        # scaler.update()\n",
    "      train_avg_loss += loss.item()\n",
    "    train_avg_loss /= len(dataset['train'])\n",
    "    total_train_loss.append(train_avg_loss)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    test_avg_loss = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "      for idx, row in tqdm(enumerate(dataset['test']), total=len(dataset['test'])):\n",
    "\n",
    "        input = torch.tensor(row['data']).unsqueeze(0).unsqueeze(0).to(device)\n",
    "        label = id2label[int(row['label'])]\n",
    "\n",
    "        val_outputs = model(input)\n",
    "        val_loss = loss_fn(val_outputs, F.one_hot(torch.tensor(label), 3).float().to(device))\n",
    "\n",
    "        y_true.append(label)\n",
    "        y_pred.append(torch.argmax(val_outputs.to('cpu'), -1))\n",
    "        \n",
    "        test_avg_loss += val_loss.item()\n",
    "          \n",
    "      test_avg_loss /= len(dataset['test'])\n",
    "      total_test_loss.append(test_avg_loss)\n",
    "\n",
    "      f1score = f1_score(y_true=y_true, y_pred=y_pred, average='macro')\n",
    "      total_f1.append(f1score)\n",
    "\n",
    "      print(f\"Epoch {epoch+1}/{num_epochs}: Avg Loss: {train_avg_loss}, Avg Val Loss: {test_avg_loss}, \\ntF1_score: {f1_score(y_true=ty_true, y_pred=ty_pred, average='macro')}, vF1_score: {f1score}\")\n",
    "      \n",
    "      # early stop\n",
    "      \n",
    "      torch.save(model, f'tst_model_a{epoch}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(total_train_loss)\n",
    "plt.plot(total_test_loss)\n",
    "plt.plot(total_f1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.load('test_model_a134.pt') # this model is better in public\n",
    "model = torch.load('tst_model103.pt') # but this model in private"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# If the dataset is gated/private, make sure you have run huggingface-cli login\n",
    "dataset = load_dataset(\"Expss4/EXP-Last-Place-Test\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {110:0, 120:1, 150:2}\n",
    "label2id = {0:110, 1:120, 2:150}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "      for idx, row in tqdm(enumerate(dataset['train']), total=len(dataset['train'])):\n",
    "\n",
    "        input = torch.tensor(row['data']).unsqueeze(0).unsqueeze(0).to(device)\n",
    "\n",
    "        val_outputs = model(input)\n",
    "        y_pred.append(label2id[int(torch.argmax(val_outputs.to('cpu'), -1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sub = pd.read_csv('sample_submission.csv')\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_test = [example['id'] for example in dataset['train']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = id_test\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'predict': y_pred,\n",
    "    'id': p\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.merge(sub, df[['id', 'predict']], on='id', how='left')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.drop('predict_x', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.rename(columns={'predict_y': 'predict'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.loc[0:2, 'predict'] = [110, 150, 150]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('mixueicecreamcha103.csv',index= False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
